{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an MNIST Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhsilva2912/MIT_ComputerVision/blob/main/Building_an_MNIST_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BTIAeOuhwa"
      },
      "source": [
        "## NOTE: Click the top-left \"Open In Playground\" button! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b1o-YeTJDv"
      },
      "source": [
        "# install basical image libs\n",
        "!pip install Pillow>=5.0.0\n",
        "!pip install -U image\n",
        "\n",
        "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13PbnpgoQNha"
      },
      "source": [
        "## Building an MNIST Classifier\n",
        "\n",
        "\n",
        "Using what we have learned, let's build a simple MNIST digits classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0tjLy2VUkj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f6eG5KSOKw"
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "The [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html) library provides a wide range of standard vision datasets and networks with pretrained weights. We will use [the `torchvision.datasets.MNIST` class](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) to easily access the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YutSDfPfR_Eg"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGQ7wf5S-g7"
      },
      "source": [
        "Each element of the dataset is a 2-tuple, consisting of the image of the digit, and its label. E.g.,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpK3WQnMSxDh"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print('This is a digit {}:'.format(label))\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7XDKYoTKER"
      },
      "source": [
        "type(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDgAtpx9TaJk"
      },
      "source": [
        "The image is given as a `PIL.Image`. To automatically obtain a `torch.Tensor`, we can add a [`torchvision.transforms.ToTensor` ](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor) transform when constructing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLnprU5TcPW"
      },
      "source": [
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=torchvision.transforms.ToTensor())  # the ToTensor transform converts PIL.Image to torch.Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_S3CyfdTvYv"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print(type(image))\n",
        "print(image.shape)  # MNIST images are 28x28, and have a single channel representing brightness."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxpkn2MTw8x"
      },
      "source": [
        "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlxkKkiUbT9"
      },
      "source": [
        "In deep learning, it is often a good idea to normalize network inputs to be centered around zero. We use the [`torchvision.transforms.Normalize`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) tranform to achieve this. Adding this transform, we construct the dataset as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUana9IuVQ_l"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
        "])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=transform)\n",
        "mnist_val = torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
        "                                         transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6732k7jSDze"
      },
      "source": [
        "print('training set size:\\t{}'.format(len(mnist_train)))\n",
        "print('validation set size:\\t{}'.format(len(mnist_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_zABI6VzqM"
      },
      "source": [
        "We use the PyTorch `torch.utils.data.DataLoader` to automatically load batched data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfqlx7jDUK_C"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True,                   # shuffle training set\n",
        "                                           num_workers=4,                  # turns on multi-processing loading so training is not blocked by data loading\n",
        "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
        "val_loader = torch.utils.data.DataLoader(mnist_val, \n",
        "                                         batch_size=batch_size, \n",
        "                                         num_workers=4, \n",
        "                                         pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwhWLUYa_jj"
      },
      "source": [
        "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple, \n",
        "# but now consisting of a batched image tensor, and a batched label tensor.\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print('batched image tensor shape: {}'.format(images.shape))\n",
        "print('batched label tensor shape: {}'.format(labels.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vtmrt4RWkYi"
      },
      "source": [
        "### Building the Network\n",
        "\n",
        "We will use a convolutional network for classification. The following architecture is adapted from the famous [LeNet-5](https://ieeexplore.ieee.org/document/726791) [1].\n",
        "\n",
        "\n",
        "It is okay if you don't understand how convolution works. Don't worry! Tomorrow's lecture will cover that. :)\n",
        "\n",
        "\n",
        "\n",
        "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGKK2QIWgyI"
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h260SpqhYkGL"
      },
      "source": [
        "net = MyNet().to(cuda0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQCUclhOZ4zS"
      },
      "source": [
        "# This network output a size 10 vector for each input image, as verified below \n",
        "# using a random input tensor.\n",
        "\n",
        "net(torch.randn(32, 1, 28, 28, device=cuda0)).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2horeRUtaD7R"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "\n",
        "For classification, we will use the cross-entropy loss [`F.cross_entropy`](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy) to train this network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPbQzcJbvnj"
      },
      "source": [
        "We can write a function that iterates through the training set (via `train_loader`) and train for 1 epoch. The code is extremely similar to what we did for approximating $f(x) = \\cos(x)$, only with new ways to load data and compute loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BrV5UGaIXj"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def train(net, optim):\n",
        "    net.train()\n",
        "    for image, label in train_loader:\n",
        "        # put data onto GPU\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # clear gradient\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # forward through the network\n",
        "        # FIXME!!!\n",
        "        \n",
        "        # compute loss and gradient\n",
        "        # FIXME!!! Check the `F.cross_entropy` documentation linked above\n",
        "        \n",
        "        # update parameters\n",
        "        # FIXME!!!\n",
        "        \n",
        "        pass  # FIXME!!! Remove this `pass` when you are done."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_TGTEcj2J"
      },
      "source": [
        "Let's also write a function that evaluates our network on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wHW_UObnAk"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def evaluate(net):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    net.eval()  # puts the network in eval mode. this is important when the \n",
        "                # network has layers that behaves differently in training and \n",
        "                # evaluation time, e.g., dropout and batch norm.\n",
        "    for image, label in val_loader:\n",
        "        # put data onto GPU\n",
        "        # FIXME!!!\n",
        "        \n",
        "        with torch.no_grad():  # gradients are not tracked in this context manager\n",
        "                               # since we are evaluating, gradients are not needed \n",
        "                               # and we can save some time and GPU memory.\n",
        "              \n",
        "            # forward through the network, and get the predicted class\n",
        "            # FIXME!!!  (HINT: use .argmax(dim=-1))\n",
        "            #   `prediction` should be an integer vector of size equal to the batch size.\n",
        "            #   Remember that the network outputs logits of the prediction probabilities, \n",
        "            #   and that the higher the logits, the higher the probability.\n",
        "            prediction = None  \n",
        "            \n",
        "            total += image.size(0)  # batch size\n",
        "            correct += (prediction == label).sum().item()  # `.item()` retreives a python number from a 1-element tensor\n",
        "            \n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7PVIwJdrKl"
      },
      "source": [
        "# Without any training, the network accuracy matches that of random guessing: ~10%.\n",
        "\n",
        "print('At initialization, the network has accuracy {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOd5vtSOeI1T"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7n0x8idsDJ"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 0.1\n",
        "\n",
        "optim = None  # FIXME!!! Construct an optimizer (e.g., SGD) to optimize the network parameters with the above learning rate\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: {}\\tValidation Accuracy: {:.4f}%'.format(epoch, evaluate(net) * 100))\n",
        "    train(net, optim)\n",
        "\n",
        "print('Done! \\tValidation Accuracy: {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEuCz50os93"
      },
      "source": [
        "## Open-ended Exercises (not required)\n",
        "\n",
        "1. What could you do to make the accuracy higher and/or the training faster?  \n",
        "2. Adapt the code for another dataset (e.g., CIFAR-10 from [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)).\n",
        "3. How dose your MNIST perform on [the USPS dataset](https://gist.github.com/SsnL/300865932b090d3f0798c2b961d371f9) (another black-white digits dataset)? Why?\n",
        "4. How many samples are actually needed to train a good MNIST classifier? Try subsample the training set (sampled a fraction of images per class) and plot validation accuracy vs. training set size.\n",
        "5. Use the [fast-gradient sign method](https://arxiv.org/abs/1412.6572) to attack your MNIST classifier! Why does your super great classifier now fail at a seemingly normal digit image?"
      ]
    }
  ]
}