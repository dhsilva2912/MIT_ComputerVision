{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an MNIST Classifier (Solution)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhsilva2912/MIT_ComputerVision/blob/main/Building_an_MNIST_Classifier_(Solution).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8BTIAeOuhwa"
      },
      "source": [
        "## NOTE: Click the top-left \"Open In Playground\" button! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6b1o-YeTJDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c2e0960a-40bb-4629-f0c1-f610baaeb3f9"
      },
      "source": [
        "# install basical image libs\n",
        "!pip install Pillow>=5.0.0\n",
        "!pip install -U image\n",
        "\n",
        "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied, skipping upgrade: django in /usr/local/lib/python3.6/dist-packages (from image) (2.2.3)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: sqlparse in /usr/local/lib/python3.6/dist-packages (from django->image) (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13PbnpgoQNha"
      },
      "source": [
        "## Building an MNIST Classifier\n",
        "\n",
        "\n",
        "Using what we have learned, let's build a simple MNIST digits classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0tjLy2VUkj"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(1234)  # for reproducibility\n",
        "\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f6eG5KSOKw"
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "The [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html) library provides a wide range of standard vision datasets and networks with pretrained weights. We will use [the `torchvision.datasets.MNIST` class](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) to easily access the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YutSDfPfR_Eg"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGQ7wf5S-g7"
      },
      "source": [
        "Each element of the dataset is a 2-tuple, consisting of the image of the digit, and its label. E.g.,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpK3WQnMSxDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "fa1ea64a-a748-4606-9946-ce43f751b98b"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print('This is a digit {}:'.format(label))\n",
        "image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a digit 6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+UlEQVR4nNWPoUtDYRTFTxC0CIJh\nQcS0l8aYGPSF8TBOhWX/gxXZUxSbQcOKzVWbJmGMLQ/TXDVtZbyhbGEWnwtazvEzCML7tq+teNLl\n/rjnngPMTV704mQ3b6w7UKotPq86LBvU2a7j0Cd16MwiFV1hrthcc7Gnz346uVn4m4rb5uHLAVfy\nwPsQQHkdp7bp8qPRDnByHEnGfn1ADdLI1chJV52N5OERh5fw7jW+2wzUTcICeYFUg3F1MdOLq0nX\ncxJokwF88tp6WVENuZFCeJHCqSrGAN8m+7o0yH/YTXzSL8Wkxns2ArYmFEnaWX613xJ5Gwaz2P/Q\nDwv6bXmT2FBqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F2691F82CC0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7XDKYoTKER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c84ace18-2cfc-45a4-e950-cccabadbb4b3"
      },
      "source": [
        "type(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDgAtpx9TaJk"
      },
      "source": [
        "The image is given as a `PIL.Image`. To automatically obtain a `torch.Tensor`, we can add a [`torchvision.transforms.ToTensor` ](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor) transform when constructing the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLnprU5TcPW"
      },
      "source": [
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=torchvision.transforms.ToTensor())  # the ToTensor transform converts PIL.Image to torch.Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_S3CyfdTvYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "463adada-26a4-445a-c593-3565360e6fa7"
      },
      "source": [
        "image, label = mnist_train[13]\n",
        "print(type(image))\n",
        "print(image.shape)  # MNIST images are 28x28, and have a single channel representing brightness."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxpkn2MTw8x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "712c54f5-8c3c-4a1a-d461-e037e4ff9b86"
      },
      "source": [
        "print('This image has max={}'.format(image.max()), 'and min={}'.format(image.min()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image has max=1.0 and min=0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVlxkKkiUbT9"
      },
      "source": [
        "In deep learning, it is often a good idea to normalize network inputs to be centered around zero. We use the [`torchvision.transforms.Normalize`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) tranform to achieve this. Adding this transform, we construct the dataset as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUana9IuVQ_l"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
        "])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=transform)\n",
        "mnist_val = torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
        "                                         transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6732k7jSDze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2c4ab75c-9e78-43e8-9e3e-d212a1bf7f3d"
      },
      "source": [
        "print('training set size:\\t{}'.format(len(mnist_train)))\n",
        "print('validation set size:\\t{}'.format(len(mnist_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training set size:\t60000\n",
            "validation set size:\t10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_zABI6VzqM"
      },
      "source": [
        "We use the PyTorch `torch.utils.data.DataLoader` to automatically load batched data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfqlx7jDUK_C"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, \n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,                   # shuffle training set\n",
        "                                           num_workers=4,                  # turns on multi-processing loading so training is not blocked by data loading\n",
        "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
        "val_loader = torch.utils.data.DataLoader(mnist_val, \n",
        "                                         batch_size=batch_size, \n",
        "                                         num_workers=4, \n",
        "                                         pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfwhWLUYa_jj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "66a9a003-55a0-45ff-ad8b-f24072f3bca5"
      },
      "source": [
        "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple, \n",
        "# but now consisting of a batched image tensor, and a batched label tensor.\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print('batched image tensor shape: {}'.format(images.shape))\n",
        "print('batched label tensor shape: {}'.format(labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batched image tensor shape: torch.Size([512, 1, 28, 28])\n",
            "batched label tensor shape: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vtmrt4RWkYi"
      },
      "source": [
        "### Building the Network\n",
        "\n",
        "We will use a convolutional network for classification. The following architecture is adapted from the famous [LeNet-5](https://ieeexplore.ieee.org/document/726791) [1].\n",
        "\n",
        "\n",
        "It is okay if you don't understand how convolution works. Don't worry! Tomorrow's lecture will cover that. :)\n",
        "\n",
        "\n",
        "\n",
        "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sGKK2QIWgyI"
      },
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h260SpqhYkGL"
      },
      "source": [
        "net = MyNet().to(cuda0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQCUclhOZ4zS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a99bfd2a-9996-4b86-bdfa-b0ce18f8a9f4"
      },
      "source": [
        "# This network output a size 10 vector for each input image, as verified below \n",
        "# using a random input tensor.\n",
        "\n",
        "random_input = torch.randn(123, 1, 28, 28, device=cuda0)\n",
        "output = net(random_input)\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([123, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2horeRUtaD7R"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "\n",
        "For classification, we will use the cross-entropy loss [`F.cross_entropy`](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy) to train this network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxPbQzcJbvnj"
      },
      "source": [
        "We can write a function that iterates through the training set (via `train_loader`) and train for 1 epoch. The code is extremely similar to what we did for approximating $f(x) = \\cos(x)$, only with new ways to load data and compute loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BrV5UGaIXj"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def train(net, optim):\n",
        "    net.train()\n",
        "    for image_cpu, label_cpu in train_loader:\n",
        "        # put data onto GPU\n",
        "        image = image_cpu.to(cuda0)\n",
        "        label = label_cpu.to(cuda0)\n",
        "        \n",
        "        # clear gradient\n",
        "        optim.zero_grad()\n",
        "        \n",
        "        # forward through the network\n",
        "        output = net(image)\n",
        "        \n",
        "        # compute loss and gradient\n",
        "        loss = F.cross_entropy(output, label)\n",
        "        loss.backward()\n",
        "        \n",
        "        # update parameters\n",
        "        optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_TGTEcj2J"
      },
      "source": [
        "Let's also write a function that evaluates our network on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wHW_UObnAk"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "def evaluate(net):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    net.eval()  # puts the network in eval mode. this is important when the \n",
        "                # network has layers that behaves differently in training and \n",
        "                # evaluation time, e.g., dropout and batch norm.\n",
        "    for image_cpu, label_cpu in val_loader:\n",
        "        # put data onto GPU\n",
        "        image = image_cpu.to(cuda0)\n",
        "        label = label_cpu.to(cuda0)\n",
        "        \n",
        "        with torch.no_grad():  # gradients are not tracked in this context manager\n",
        "                               # since we are evaluating, gradients are not needed \n",
        "                               # and we can save some time and GPU memory.\n",
        "              \n",
        "            # forward through the network, and get the predicted class\n",
        "            prediction = net(image).argmax(dim=-1)  \n",
        "            \n",
        "            total += image.size(0)  # batch size\n",
        "            correct += (prediction == label).sum().item()  # `.item()` retreives a python number from a 1-element tensor\n",
        "            \n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7PVIwJdrKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c53d3778-4744-48aa-dfb1-861ab7c8d9be"
      },
      "source": [
        "# Without any training, the network accuracy matches that of random guessing: ~10%.\n",
        "\n",
        "print('At initialization, the network has accuracy {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At initialization, the network has accuracy 8.9300%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOd5vtSOeI1T"
      },
      "source": [
        "### Putting Everything Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7n0x8idsDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "04642bf4-69dc-421f-afe0-00c340fbd101"
      },
      "source": [
        "########################\n",
        "#                      #\n",
        "#       Exercise       #\n",
        "#                      #\n",
        "########################\n",
        "\n",
        "# Fix the places with a `FIXME!!!`\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 0.1\n",
        "\n",
        "optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch: {}\\tValidation Accuracy: {:.4f}%'.format(epoch, evaluate(net) * 100))\n",
        "    train(net, optim)\n",
        "\n",
        "print('Done! \\tValidation Accuracy: {:.4f}%'.format(evaluate(net) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\tValidation Accuracy: 8.9300%\n",
            "Epoch: 1\tValidation Accuracy: 83.4000%\n",
            "Epoch: 2\tValidation Accuracy: 93.4800%\n",
            "Epoch: 3\tValidation Accuracy: 96.5300%\n",
            "Epoch: 4\tValidation Accuracy: 97.5400%\n",
            "Epoch: 5\tValidation Accuracy: 97.5100%\n",
            "Epoch: 6\tValidation Accuracy: 98.4100%\n",
            "Epoch: 7\tValidation Accuracy: 98.3500%\n",
            "Epoch: 8\tValidation Accuracy: 98.4200%\n",
            "Epoch: 9\tValidation Accuracy: 98.4100%\n",
            "Done! \tValidation Accuracy: 98.4200%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEuCz50os93"
      },
      "source": [
        "## Open-ended Exercises (not required)\n",
        "\n",
        "1. What could you do to make the accuracy higher and/or the training faster?  \n",
        "2. Adapt the code for another dataset (e.g., CIFAR-10 from [`torchvision.datasets`](https://pytorch.org/docs/stable/torchvision/datasets.html)).\n",
        "3. How dose your MNIST perform on [the USPS dataset](https://gist.github.com/SsnL/300865932b090d3f0798c2b961d371f9) (another black-white digits dataset)? Why?\n",
        "4. How many samples are actually needed to train a good MNIST classifier? Try subsample the training set (sampled a fraction of images per class) and plot validation accuracy vs. training set size.\n",
        "5. Use the [fast-gradient sign method](https://arxiv.org/abs/1412.6572) to attack your MNIST classifier! Why does your super great classifier now fail at a seemingly normal digit image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB6zyzMjJ7yC"
      },
      "source": [
        "# Fast-Gradient Sign Attack example\n",
        "\n",
        "import PIL\n",
        "\n",
        "# Utility function\n",
        "def tensor2image(tensor):\n",
        "    return PIL.Image.fromarray((tensor.detach() * 127.5 + 128).clamp_(0, 255).to('cpu', torch.uint8).numpy()[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5NfRhGoKn2H"
      },
      "source": [
        "# Get a data sample we want to attack\n",
        "\n",
        "data, label = mnist_val[245]\n",
        "data = data.to(cuda0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiThr85eKqqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "24d8ca66-23ac-4bb3-8b82-677a978adb02"
      },
      "source": [
        "# Look at the image\n",
        "\n",
        "tensor2image(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3UlEQVR4nGNgGCAwH5/kL2c8kmkX\nNbGKMzIwMDAwTFLczsD4n0HK/3DrUwwlKov+/r3y8O/fdf/tsRjAZm/PIJptH/QXmyQEWP/8ZYVL\nTnPfn2IGM+xyAff//Flx+dvly9nuGHKX/v79+/dKsykDg13viznsqJK3/lzqhTlH88EcVEkeUW44\nm2nDH5yuZij/8winXMnPR1pIXKe/f1VgbJVLf+8HIKtla33/ebY2AwODQ9y+T3/3akBEGWHSgk7a\niZwMjHwsb1ZsOvIbTZKBgUFLi8GWY8tm3O4c3AAA5FBInrt1qJoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9928680E80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPF4q7v2Ktz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b099558d-5421-4495-bb92-5667138c7f27"
      },
      "source": [
        "# Label is...\n",
        "\n",
        "print('label is', label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg-QAwN2LF0x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fc982b1-1a58-4423-a19d-43b5504ecbaa"
      },
      "source": [
        "# Let's see what our trained network says about this image.\n",
        "\n",
        "\n",
        "# turn the network into eval mode\n",
        "net.eval()\n",
        "output = net(data.unsqueeze(0))  # .unsqueeze(0) insert a batch dimension so it looks like batched data\n",
        "prediction = output.argmax(-1)\n",
        "print('predicted class is', prediction.item())\n",
        "assert prediction.item() == label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS9BvDW8Mezz"
      },
      "source": [
        "# For fast-gradient sign attack to work, we need to get the gradient w.r.t. the input image. \n",
        "\n",
        "\n",
        "# Let's make it accept gradient first.\n",
        "data = data.requires_grad_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7YRbcP8NBmR"
      },
      "source": [
        "# Compute the loss as usual\n",
        "loss = F.cross_entropy(net(data.unsqueeze(0)), torch.tensor([label], device=cuda0))\n",
        "\n",
        "# backprop, now to `data` as well\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHqqxmvyNW3s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe7f1f8c-19c2-4b9e-e0b2-fe7830f7f47a"
      },
      "source": [
        "eps = 0.15\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Fast-gradient sign attack (aka gradient **ascent** for loss maximization)\n",
        "    new_data = (data + data.grad.sign() * eps).clamp_(-1, 1)  \n",
        "    new_prediction = net(new_data.unsqueeze(0)).argmax(-1)\n",
        "    print('The network predicts the attacked image as', new_prediction.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The network predicts the attacked image as 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MysfJQzBNZ2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "3461a716-84b4-4407-972b-582abbc6b786"
      },
      "source": [
        "# visualize the attacked image\n",
        "\n",
        "tensor2image(new_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABaUlEQVR4nJVSPUsDQRB9e6RQEEUe\nfhBsVAiYRGyUFMbKxkYLBbGV+AO0NL0ftZXoHxBBA6JYmiBYG9BGrMQQPDKNhiBYjMXt3p2JCL5m\n9+7N7MybN4YCEICAEFAo7g/EUAgLcZeAg3j4A8YGSgdDCAjgggRBso33QGBm/mfKD2y/5iMqyqcB\nARyMXj8ZTSUnbnc+GdYnSJK5K/XrTdVKIxt/1lhJy6gMrD7waLIeCWYYRwBLqou0RUkGpA0YrL7t\nctwxJD2xzxCF52H0nZXL5bXpcCSu9Zr6vl/ZHAMyxcdSkoxxEL0pZhkMavCjRNutAAB7ulsvrrp3\nnkoDSMBZ1myG5slGvgUAntjE+FD3ju8XYtOdUs05CbmavhcCkVbroer+MMiVrarq6Sxj4xOifySz\n3g3Tm2icXPhfQS27Q0IIhtKY67q8AwWggDCUcMVCq1yLxn5ac0Ah3HJKIvIkONr36Hd0rNt/8A3G\nUng8x1UXKwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F992862C668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rco3i5NO8Gp"
      },
      "source": [
        "# It still looks like a 3! But our network is now fooled..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaeiM9a-QEGL"
      },
      "source": [
        "Questions: \n",
        "+ Why does this happen? \n",
        "+ This method attacks the network so it predicts wrongly for this 3 image. Can you attack the network so it outputs a particular target class?"
      ]
    }
  ]
}