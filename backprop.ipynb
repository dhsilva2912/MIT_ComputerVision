{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backprop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhsilva2912/MIT_ComputerVision/blob/main/backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9LTqgrvF5Bm"
      },
      "source": [
        "import numpy as np              # numerical computing library\n",
        "import matplotlib.pyplot as plt # plotting library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeEJshQGKJx"
      },
      "source": [
        "# create some random data\n",
        "np.random.seed(0) # set random seed for reproducibility\n",
        "Ndatapoints = 100\n",
        "x = np.random.randn(Ndatapoints,1)\n",
        "y = 0.5*x**2 + 0.2*np.random.randn(Ndatapoints,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-uSl_L4GMGc"
      },
      "source": [
        "# implement a neural net with forward and backward functions\n",
        "class Linear():\n",
        "  def __init__(self, N, M): # N is dimensionality of the input, M is dimensionality of the output\n",
        "    self.N = N\n",
        "    self.M = M\n",
        "    self.W = np.random.randn(M, N)\n",
        "    self.b = np.random.randn(M,1)\n",
        "    self.x_in = np.zeros((N,1))\n",
        "    self.x_out = np.zeros((M,1))\n",
        "  def forward(self, x):\n",
        "    self.x_in = x\n",
        "    self.x_out = np.matmul(self.W,self.x_in) + self.b\n",
        "    return self.x_out\n",
        "  def backward(self): # returns dLdx, x_in, dLdb\n",
        "    return self.W, self.x_in, np.eye(self.M)\n",
        "\n",
        "class Relu():\n",
        "  def __init__(self, dim):\n",
        "    self.x_in = np.zeros((dim,1))\n",
        "    self.x_out = np.zeros((dim,1))\n",
        "  def forward(self, x):\n",
        "    self.x_in = x\n",
        "    self.x_out = np.maximum(self.x_in,0)\n",
        "    return self.x_out\n",
        "  def backward(self): # returns dLdx\n",
        "    return np.diag((self.x_in>=0).astype(np.float32)[:,0])\n",
        "\n",
        "class Net():\n",
        "  def __init__(self, in_dim, hid_dim, out_dim, lr=0.0001):\n",
        "    self.l1 = Linear(in_dim, hid_dim)\n",
        "    self.r1 = Relu(hid_dim)\n",
        "    self.l2 = Linear(hid_dim, hid_dim)\n",
        "    self.r2 = Relu(hid_dim)\n",
        "    self.l3 = Linear(hid_dim, out_dim)\n",
        "\n",
        "    self.layers = [self.l1, self.r1, self.l2, self.r2, self.l3]\n",
        "\n",
        "    self.lr = lr # learning rate\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_in = x\n",
        "    for layer in self.layers:\n",
        "      x_out = layer.forward(x_in)\n",
        "      x_in = x_out.copy()\n",
        "    y = x_out\n",
        "    return y\n",
        "  \n",
        "  def backward(self, dLdout):\n",
        "\n",
        "    for layer in self.layers[::-1]:\n",
        "      \n",
        "      if isinstance(layer, Linear):\n",
        "\n",
        "        # compute gradients for the layer\n",
        "        doutdin, x_in, doutdb  = layer.backward()\n",
        "        dLdin = np.matmul(dLdout, doutdin)\n",
        "        dLdW = np.matmul(x_in, dLdout)\n",
        "        dLdb = np.matmul(dLdout, doutdb)\n",
        "\n",
        "        # take a gradient step\n",
        "        layer.W -= self.lr*np.transpose(dLdW)\n",
        "        #layer.b -= self.lr*np.transpose(dLdb)\n",
        "\n",
        "      elif isinstance(layer, Relu):\n",
        "        doutdin = layer.backward()\n",
        "        dLdin = np.matmul(dLdout, doutdin)\n",
        "      \n",
        "      else: print('unrecognized layer type')\n",
        "      \n",
        "      # move on to next layer\n",
        "      dLdout = np.copy(dLdin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABTC6srK7yZ8"
      },
      "source": [
        "# instantiate a net\n",
        "net = Net(1,128,1,0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wR7exVG7SYU"
      },
      "source": [
        "# plot the data\n",
        "def plot_data(x,y):\n",
        "  plt.plot(x, y, 'o', markersize=5)\n",
        "  plt.axis('equal')\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "\n",
        "# plot the mapping the net performs over some interval\n",
        "def plot_net(net):\n",
        "  x_grid = np.expand_dims(np.arange(np.floor(np.min(x)),np.ceil(np.max(x)),0.1), axis=1)\n",
        "  y_grid = np.zeros_like(x_grid)\n",
        "\n",
        "  for i in range(y_grid.shape[0]): # produce y = f(x) for each x\n",
        "    y_grid[[i]] = net.forward(x_grid[[i]])\n",
        "  plt.plot(x_grid, y_grid)\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('f(x)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXvIA8i3pup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e4fecdc5-c820-48e0-a08b-93f21ba0bbe7"
      },
      "source": [
        "# fit the net to the data, using backprop\n",
        "Nepochs = 10\n",
        "for b in range(Nepochs):\n",
        "  J = 0\n",
        "  for i in range(x.shape[0]):\n",
        "    y_pred = net.forward(x[[i]])\n",
        "    L = ((y_pred-y[i])**2) # mse loss\n",
        "    J += L[0,0]\n",
        "    dLdy_pred = 2*(y_pred-y[i])\n",
        "    net.backward(dLdy_pred)\n",
        "  if (b % 1)==0: print('Total loss: {:1.2f}'.format(J))\n",
        "\n",
        "# plot\n",
        "plot_data(x,y)\n",
        "plot_net(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total loss: 11831.66\n",
            "Total loss: 7850.37\n",
            "Total loss: 6232.94\n",
            "Total loss: 5458.43\n",
            "Total loss: 4990.65\n",
            "Total loss: 4641.24\n",
            "Total loss: 4344.08\n",
            "Total loss: 4075.84\n",
            "Total loss: 3827.99\n",
            "Total loss: 3597.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Gc5n_dJ-GY"
      },
      "source": [
        "# additional exercises\n",
        "# 1. add weight decay or dropout to regularize the network\n",
        "# 2. rewrite the training using different sized batches to compute each gradient update\n",
        "# 3. define a new layer type (e.g., softmax, L2-norm, etc) and write the backprop update for it"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}