{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhsilva2912/MIT_ComputerVision/blob/main/intro_to_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7IhKk928pAq"
      },
      "source": [
        "import numpy as np              # numerical computing library\n",
        "import matplotlib.pyplot as plt # plotting library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVVam2M49DI5",
        "cellView": "code"
      },
      "source": [
        "# create some random data\n",
        "np.random.seed(0) # set random seed for reproducibility\n",
        "Ndatapoints = 30\n",
        "x = np.random.randn(Ndatapoints,1)\n",
        "y = 2*x + 0.5*np.random.randn(Ndatapoints,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWz8ATkH_jSR"
      },
      "source": [
        "# plot the data\n",
        "def my_plot(x,y,w=None):\n",
        "  plt.plot(x, y, 'o', markersize=5)\n",
        "  if w is not None:\n",
        "    plt.plot(x,w*x, color=[0.3,0.3,0.3], linewidth=1)\n",
        "  plt.axis('equal')\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "\n",
        "my_plot(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nihds7ySAnrB"
      },
      "source": [
        "# now we will try to fit a line to the data, i.e. model y = w*x\n",
        "# first let's start with a simple guess, w = 1, and check how well it does\n",
        "def check(x,y,w):\n",
        "  mse = ((w*x-y)**2).sum()\n",
        "  return mse\n",
        "\n",
        "w = 1\n",
        "my_plot(x,y,w)\n",
        "print('Mean squared error: {:1.2f}'.format(check(x,y,w)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv3VGKDZB7n4"
      },
      "source": [
        "# let's consider the hypothesis space y = w*x, parameterized by w\n",
        "# let our objective be to minimize mean squared error (mse)\n",
        "# we will start with the simplest optimizer possible: guess and check!\n",
        "\n",
        "def guess():\n",
        "  w = np.random.randn(1)\n",
        "  return w\n",
        "\n",
        "Ntrials = 100\n",
        "mse_best, w_best = None, None\n",
        "for i in range(Ntrials):\n",
        "  w = guess()\n",
        "  mse = check(x,y,w)\n",
        "  if mse_best is None or mse < mse_best:\n",
        "    mse_best = mse\n",
        "    w_best = w\n",
        "\n",
        "my_plot(x,y,w_best)\n",
        "print('Mean squared error: {:1.2f}'.format(check(x,y,w_best)))\n",
        "\n",
        "# --> to do: try replacing mse with mean absolute error, and see how the result differs; try some other objective functions of your choice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufXc4BPZNgOc"
      },
      "source": [
        "# Guess and check worked! \n",
        "# If you ever feel lost about how to solve a problem, remember that guess and check is always an option and often not a bad one. \n",
        "# Better optimization algorithms are essentially exploiting structure in the \"check\" function, such as the ability to take its gradient.\n",
        "#\n",
        "# In the lecture slides, we worked out a closed form solution to the linear least squares problem, w = (X'X)^-1 X'y, which we write in code as:\n",
        "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(x), x)), np.transpose(x)) ,y)\n",
        "\n",
        "my_plot(x,y,w)\n",
        "print('Mean squared error: {:1.2f}'.format(check(x,y,w)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJbQMZVDSu9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}